{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from community import community_louvain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna(subset=['Name', 'Country', 'Subscribers', 'Category_2'])\n",
    "\n",
    "    for col in ['Subscribers', 'Avg. views', 'Avg. likes', 'Avg Comments']:\n",
    "        df[col] = df[col].astype(str).str.replace(',', '')\n",
    "        df[col] = df[col].apply(lambda x: float(x[:-1]) * 1000 if x.endswith('K') else\n",
    "                                float(x[:-1]) * 1_000_000 if x.endswith('M') else\n",
    "                                float(x) if x else 0)\n",
    "\n",
    "    df.fillna({'Avg Comments': 0, 'Avg. likes': 0, 'Avg. views': 0}, inplace=True)\n",
    "    df['Engagement Rate'] = df['Avg. likes'] / df['Avg. views']\n",
    "    df['Comment Rate'] = df['Avg Comments'] / df['Avg. views']\n",
    "    return df\n",
    "\n",
    "def detect_anomalies(df, z_threshold=3):\n",
    "    df['Engagement_Z'] = (df['Engagement Rate'] - df['Engagement Rate'].mean()) / df['Engagement Rate'].std()\n",
    "    df['Comment_Z'] = (df['Comment Rate'] - df['Comment Rate'].mean()) / df['Comment Rate'].std()\n",
    "    df['Anomaly'] = ((df['Engagement_Z'].abs() > z_threshold) | \n",
    "                     (df['Comment_Z'].abs() > z_threshold)).astype(int)\n",
    "    suspicious = df[df['Anomaly'] == 1]\n",
    "    print(f\"\\n Detected {len(suspicious)} suspicious influencers (potential fake engagement):\")\n",
    "    print(suspicious[['Name', 'Engagement Rate', 'Comment Rate', 'Engagement_Z', 'Comment_Z']])\n",
    "    return df\n",
    "\n",
    "def build_graph(df):\n",
    "    G = nx.Graph()\n",
    "    CATEGORY_WEIGHT = 0.5\n",
    "    COUNTRY_WEIGHT = 0.05\n",
    "    SUBSCRIBER_WEIGHT = 0.15\n",
    "    ENGAGEMENT_WEIGHT = 0.3\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        G.add_node(row['Name'], subscribers=row['Subscribers'], category=row['Category_2'],\n",
    "                   country=row['Country'], views=row['Avg. views'], likes=row['Avg. likes'],\n",
    "                   comments=row['Avg Comments'], engagement_rate=row['Engagement Rate'],\n",
    "                   comment_rate=row['Comment Rate'])\n",
    "\n",
    "    for i, row1 in df.iterrows():\n",
    "        for j, row2 in df.iterrows():\n",
    "            if i < j:\n",
    "                similarity = 0\n",
    "\n",
    "                if row1['Category_2'] == row2['Category_2']:\n",
    "                    similarity += CATEGORY_WEIGHT\n",
    "                if row1['Country'] == row2['Country']:\n",
    "                    similarity += COUNTRY_WEIGHT\n",
    "                if abs(np.log10(row1['Subscribers'] + 1) - np.log10(row2['Subscribers'] + 1)) < 1:\n",
    "                    similarity += SUBSCRIBER_WEIGHT\n",
    "                if abs(row1['Engagement Rate'] - row2['Engagement Rate']) < 0.1:\n",
    "                    similarity += ENGAGEMENT_WEIGHT\n",
    "\n",
    "                if similarity > 0.2:\n",
    "                    G.add_edge(row1['Name'], row2['Name'], weight=similarity)\n",
    "    return G\n",
    "\n",
    "def calculate_network_metrics(G):\n",
    "    return {\n",
    "        'degree': nx.degree_centrality(G),\n",
    "        'betweenness': nx.betweenness_centrality(G),\n",
    "        'closeness': nx.closeness_centrality(G),\n",
    "        'eigenvector': nx.eigenvector_centrality_numpy(G),\n",
    "        'pagerank': nx.pagerank(G),\n",
    "        'community': community_louvain.best_partition(G)\n",
    "    }\n",
    "\n",
    "def find_similar_influencers(G, metrics, influencer_name, top_n=8):\n",
    "    if influencer_name not in G.nodes():\n",
    "        print(\"Influencer not found.\")\n",
    "        return None, None\n",
    "\n",
    "    target = {k: metrics[k][influencer_name] for k in metrics if k != 'community'}\n",
    "    target['community'] = metrics['community'][influencer_name]\n",
    "\n",
    "    scores = {}\n",
    "    for node in G.nodes():\n",
    "        if node == influencer_name:\n",
    "            continue\n",
    "        dist = np.sqrt(sum((metrics[k][node] - target[k])**2 for k in target if k != 'community'))\n",
    "        community_sim = 1 if metrics['community'][node] == target['community'] else 0\n",
    "        connection_bonus = 0.5 if G.has_edge(influencer_name, node) else 0\n",
    "        scores[node] = -dist + community_sim + connection_bonus\n",
    "\n",
    "    top_matches = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    subgraph = G.subgraph([influencer_name] + [x[0] for x in top_matches])\n",
    "    return top_matches, subgraph\n",
    "\n",
    "def create_metrics_table(G, metrics, similar_influencers, target_influencer):\n",
    "    influencers = [target_influencer] + [inf[0] for inf in similar_influencers]\n",
    "    return pd.DataFrame({\n",
    "        'Influencer': influencers,\n",
    "        'Degree Centrality': [metrics['degree'][inf] for inf in influencers],\n",
    "        'Betweenness Centrality': [metrics['betweenness'][inf] for inf in influencers],\n",
    "        'Closeness Centrality': [metrics['closeness'][inf] for inf in influencers],\n",
    "        'Eigenvector Centrality': [metrics['eigenvector'][inf] for inf in influencers],\n",
    "        'PageRank': [metrics['pagerank'][inf] for inf in influencers],\n",
    "        'Community': [metrics['community'][inf] for inf in influencers]\n",
    "    })\n",
    "\n",
    "def visualize_network(G, subgraph, target_influencer, metrics, similar_influencers):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    pos = nx.spring_layout(subgraph, seed=42)\n",
    "    communities = [metrics['community'][node] for node in subgraph.nodes()]\n",
    "    unique_communities = sorted(set(communities))\n",
    "    color_map = {comm: i for i, comm in enumerate(unique_communities)}\n",
    "    node_colors = [color_map[comm] for comm in communities]\n",
    "    nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors,\n",
    "                           node_size=[300 if node == target_influencer else 200 for node in subgraph.nodes()],\n",
    "                           alpha=0.8, cmap=plt.cm.tab10)\n",
    "    edge_weights = [subgraph[u][v].get('weight', 0.1) * 2 for u, v in subgraph.edges()]\n",
    "    nx.draw_networkx_edges(subgraph, pos, width=edge_weights, alpha=0.5)\n",
    "    nx.draw_networkx_labels(subgraph, pos, font_size=10, font_weight='bold')\n",
    "    plt.title(f\"Network of Similar Influencers to {target_influencer}\", fontsize=15)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('influencer_network.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_full_network(G, metrics):\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    pos = nx.spring_layout(G, k=0.15, seed=42)\n",
    "    communities = [metrics['community'][node] for node in G.nodes()]\n",
    "    unique_communities = sorted(set(communities))\n",
    "    color_map = {comm: i for i, comm in enumerate(unique_communities)}\n",
    "    node_colors = [color_map[comm] for comm in communities]\n",
    "    subscriber_counts = [G.nodes[node].get('subscribers', 10000) for node in G.nodes()]\n",
    "    min_size, max_size = 20, 300\n",
    "    if max(subscriber_counts) > min(subscriber_counts):\n",
    "        normalized_sizes = [\n",
    "            min_size + (s - min(subscriber_counts)) * (max_size - min_size) /\n",
    "            (max(subscriber_counts) - min(subscriber_counts))\n",
    "            for s in subscriber_counts\n",
    "        ]\n",
    "    else:\n",
    "        normalized_sizes = [50] * len(subscriber_counts)\n",
    "        \n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors,\n",
    "                           node_size=normalized_sizes, alpha=0.7, cmap=plt.cm.tab10)\n",
    "    nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.2)\n",
    "    plt.title(\"Full Network of YouTube Influencers\", fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('full_influencer_network.png', dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Full network saved as 'full_influencer_network.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Detected 9 suspicious influencers (potential fake engagement):\n",
      "                      Name  Engagement Rate  Comment Rate  Engagement_Z  \\\n",
      "13               BANGTANTV         0.190590      0.004051      3.821278   \n",
      "14             HYBE LABELS         0.173100      0.004500      3.356755   \n",
      "41        whinderssonnunes         0.167569      0.004560      3.209856   \n",
      "60         Kimberly Loaiza         0.194850      0.002050      3.934430   \n",
      "65             CarryMinati         0.178138      0.006919      3.490554   \n",
      "411       Pop Chartbusters         0.273713      0.001003      6.029005   \n",
      "653               Piuzinho         0.242540      0.004591      5.201069   \n",
      "676   Bispo Bruno Leonardo         0.353650      0.274343      8.152108   \n",
      "780  Pastor Antônio Júnior         0.227563      0.021600      4.803283   \n",
      "\n",
      "     Comment_Z  \n",
      "13    0.122613  \n",
      "14    0.162055  \n",
      "41    0.167303  \n",
      "60   -0.053299  \n",
      "65    0.374687  \n",
      "411  -0.145355  \n",
      "653   0.170025  \n",
      "676  23.881101  \n",
      "780   1.665158  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file_path = r'C:\\Users\\ashle\\OneDrive\\바탕 화면\\MMA\\INSY670 Social Media\\Group Assignment\\social media influencers - Youtube sep-2022 (2).csv'\n",
    "\n",
    "    df = load_and_clean_data(file_path)\n",
    "    df = detect_anomalies(df)\n",
    "    df_clean = df[df['Anomaly'] == 0]\n",
    "\n",
    "    # Store suspicious names\n",
    "    suspicious_names = set(df[df['Anomaly'] == 1]['Name'])\n",
    "\n",
    "    G = build_graph(df_clean)\n",
    "    metrics = calculate_network_metrics(G)\n",
    "\n",
    "    # Input loop\n",
    "    while True:\n",
    "        target = input(\"\\nEnter the name of the influencer you want recommendations for: \").strip()\n",
    "\n",
    "        if target in suspicious_names:\n",
    "            print(\"This influencer has been flagged for suspicious engagement. Please choose another.\")\n",
    "            continue\n",
    "        elif target not in G.nodes():\n",
    "            print(\"Influencer not found. Please enter a valid name from the cleaned network.\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    similar_influencers, subgraph = find_similar_influencers(G, metrics, target)\n",
    "\n",
    "    if similar_influencers:\n",
    "        print(f\"\\nTop recommended collaboration partners for {target}:\")\n",
    "        for i, (name, score) in enumerate(similar_influencers, 1):\n",
    "            print(f\"{i}. {name} (Score: {score:.4f})\")\n",
    "\n",
    "        table = create_metrics_table(G, metrics, similar_influencers, target)\n",
    "        print(\"\\nNetwork Metrics:\")\n",
    "        print(table.to_string(index=False))\n",
    "\n",
    "        visualize_network(G, subgraph, target, metrics, similar_influencers)\n",
    "        table.to_csv('influencer_metrics.csv', index=False)\n",
    "\n",
    "    visualize_full_network(G, metrics)\n",
    "    print(\"\\n Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Summary:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Number of nodes and edges\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal nodes (influencers): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mG\u001b[49m\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal edges (connections): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_edges()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Community detection (Louvain already in your pipeline)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of nodes and edges\n",
    "print(f\"Graph Summary:\")\n",
    "print(f\"Total nodes (influencers): {G.number_of_nodes()}\")\n",
    "print(f\"Total edges (connections): {G.number_of_edges()}\")\n",
    "\n",
    "# Community detection (Louvain already in your pipeline)\n",
    "num_communities = len(set(metrics['community'].values()))\n",
    "print(f\"Total Louvain communities detected: {num_communities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of T-Series recommendations from previous run\n",
    "recommended_names = ['Lady Diana', 'Niana Guerrero', 'Rans Entertainment',\n",
    "                     'SonyMusicIndiaVEVO', 'gymvirtual', 'Speed Records',\n",
    "                     'Dan‑Sa / Daniel Saboya', 'KAROL G']\n",
    "\n",
    "# Combine with T-Series\n",
    "target_and_recs = ['T-Series'] + recommended_names\n",
    "\n",
    "# Filter engagement rates\n",
    "engagement_subset = df[df['Name'].isin(target_and_recs)][['Name', 'Engagement Rate']]\n",
    "\n",
    "# Print with formatting\n",
    "print(\"\\n Engagement Rates of T-Series & Top Recommendations:\")\n",
    "print(engagement_subset.sort_values(by='Engagement Rate', ascending=False).to_string(index=False))\n",
    "\n",
    "mean_engagement = engagement_subset['Engagement Rate'].mean()\n",
    "print(f\"\\n Average Engagement Rate: {mean_engagement:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Average clustering coefficient\n",
    "avg_clustering = nx.average_clustering(G)\n",
    "print(f\"\\n Average Clustering Coefficient: {avg_clustering:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "community_counts = Counter(metrics['community'].values())\n",
    "print(\"\\n Top 5 Louvain Communities by Size:\")\n",
    "for comm_id, count in community_counts.most_common(5):\n",
    "    print(f\"Community {comm_id}: {count} members\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components of the Similarity Score\n",
    "In the find_similar_influencers function, the similarity score between the target influencer and other influencers is calculated using three main components:\n",
    "\n",
    "Network Metrics Distance\n",
    "This calculates the Euclidean distance between the network metrics of two influencers:\n",
    "Degree Centrality: Measures how many direct connections an influencer has. Influencers with high degree centrality are well-connected within the network.\n",
    "Betweenness Centrality: Measures how often an influencer lies on the shortest path between other influencers. High betweenness indicates an influencer who bridges different communities.\n",
    "Closeness Centrality: Measures how close an influencer is to all other influencers in the network. High closeness means an influencer can quickly reach others.\n",
    "Eigenvector Centrality: Measures an influencer's influence based on the influence of their connections. Being connected to other influential influencers increases this metric.\n",
    "PageRank: Similar to eigenvector centrality but with additional considerations for the \"importance\" of connections.\n",
    "\n",
    "A smaller distance means the influencers have similar positions and roles in the network.\n",
    "\n",
    "Community Similarity\n",
    "This is a binary score (0 or 1) that checks if two influencers belong to the same community. Communities are detected using the Louvain method, which identifies groups of influencers that are more densely connected to each other than to the rest of the network.\n",
    "Influencers in the same community often share similar characteristics, audiences, or content types, making them potentially good collaboration partners.\n",
    "\n",
    "Direct Connection Bonus\n",
    "This adds a bonus score (0.5) if the two influencers are already directly connected in the network.\n",
    "A direct connection indicates that the influencers already have some similarity based on the edge creation criteria (same category, country, subscriber range, or engagement patterns).\n",
    "\n",
    "These criteria are not equally weighted. When building the graph, each factor is assigned a fixed weight to reflect its relative importance:\n",
    "\n",
    "> Category: 0.5\n",
    "\n",
    "> Engagement Rate: 0.3\n",
    "\n",
    "> Subscriber Range: 0.15\n",
    "\n",
    "> Country: 0.05\n",
    "\n",
    "These weights prioritize content relevance and engagement over geography, leading to more meaningful recommendation connections.\n",
    "\n",
    "Additionally, the system performs anomaly detection using Z-scores on engagement rate and comment rate. Influencers who fall far outside the normal range (e.g., with extremely high engagement patterns) are flagged as suspicious and excluded from the network to ensure recommendation quality.\n",
    "\n",
    "To interpret the graph:\n",
    "Key Elements of the Graph\n",
    "\n",
    "> Nodes –\n",
    "Each node represents an influencer\n",
    "Size: The target influencer is represented by a larger node than the recommended influencers\n",
    "Color: Nodes are colored according to their community membership (influencers in the same community have the same color)\n",
    "\n",
    "> Edges (Lines) –\n",
    "Edges connect influencers who have similarity based on the criteria defined in the build_graph function\n",
    "Thickness: Thicker edges indicate stronger similarity between influencers\n",
    "The similarity is based on shared category, country, subscriber range, and engagement patterns\n",
    "\n",
    "> Labels –\n",
    "Each node is labeled with the influencer's name\n",
    "These labels help you identify specific influencers in the network\n",
    "\n",
    "> Legend –\n",
    "Located in the upper right corner\n",
    "Shows which color corresponds to which community number\n",
    "Helps you identify which influencers belong to the same community\n",
    "\n",
    "How to Interpret the Graph\n",
    "> Central Position\n",
    "Influencers positioned more centrally in the visualization are typically more connected within this specific subgraph\n",
    "The layout algorithm (spring_layout) positions nodes based on their connections, with more connected nodes often appearing more central\n",
    "\n",
    "> Clusters\n",
    "Groups of nodes positioned close together often represent influencers that are more similar to each other\n",
    "These clusters might indicate potential collaboration groups beyond just pairwise collaborations\n",
    "\n",
    "> Edge Density\n",
    "Areas with many interconnected edges indicate groups of influencers that are all similar to each other\n",
    "Sparse connections might indicate influencers that are similar to the target but not necessarily to each other\n",
    "\n",
    "Influencers with the same color belong to the same community in the larger network\n",
    "If the recommended influencers have diverse colors, it suggests the target influencer could bridge different communities\n",
    "If most recommended influencers share the same color as the target, it suggests the target is firmly embedded in one communit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
